# SSDIE-Net

## Semi-Supervised Sand-Dust Image Enhancement via Attention-Driven Multi-Scale Feature Fusion
### Authors: Mohammed Shamsaddin Qadir, Ako Bartani, Marwan Aziz Mohammed, Fatemeh Daneshfar
### Published in: Under Review

This paper proposed a semi-supervised sand-dust image enhancement method, SSDIE-Net, which integrates the strengths of supervised and unsupervised learning within a unified framework. SSDIE-Net is trained on simulated data using supervised reconstruction loss functions in the supervised branch. It integrates classical image restoration techniques with conditional adversarial networks to generate highly realistic sand-dust images. Moreover, SSDIE-Net adopts consistency regularization, dark channel priors-based regression minimization, Retinex-based pseudo-labeling, and adversarial learning to translate sand-dust images to clean ones in the unsupervised branch. Additionally, we designed an attention-based multi-scale feature fusion network in which feature map extraction from different scales facilitates improved local-to-global learning. Unlike previous methods that focus on extracting local features, SSDIE-Net learns long-range dependencies, which are essential for understanding the overall scene structure.

![Alt text](img/non_sky_page-0001.jpg)
